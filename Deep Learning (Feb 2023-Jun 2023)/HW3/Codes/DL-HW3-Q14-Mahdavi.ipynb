{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37568fcd",
   "metadata": {},
   "source": [
    "# The Deep Learning Homework 3 - Question No. 14  \n",
    "Bahar Mahdavi - SN: 40152521337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34415520",
   "metadata": {},
   "source": [
    "### We assume the equivalent weight of a convolution layer to be W, which is $W \\in \\mathbb{R}^{N\\times M \\times L \\times K}$. If we consider this tensor as the product of four one-dimensional vectors in low rank (t), so we have $Wi,j,l,k = a^i\\times b^i\\times c^i\\times d^i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9062fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dfd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VecProduct(a, b, c, d):\n",
    "    dimensions = [a.shape[0], b.shape[0], c.shape[0], d.shape[0]]\n",
    "    w = torch.tensor(a[i] * b[j] * c[l] * d[k] \n",
    "                    for k in range(dimensions[3])\n",
    "                    for l in range(dimensions[2])\n",
    "                    for j in range(dimensions[1])\n",
    "                    for i in range(dimensions[0]))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eefb6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(rank, dimN, dimM, dimL, dimK):\n",
    "    a = torch.rand(rank, dimN).requires_grad_(True)\n",
    "    b = torch.rand(rank, dimM).requires_grad_(True)\n",
    "    c = torch.rand(rank, dimL).requires_grad_(True)\n",
    "    d = torch.rand(rank, dimK).requires_grad_(True)\n",
    "\n",
    "    W = torch.zeros(dimN, dimM, dimL, dimK)\n",
    "    for t in range(rank):\n",
    "        W += torch.einsum('i,j,k,l->ijkl', a[t], b[t], c[t], d[t])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140239cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, rank, dim):\n",
    "        \n",
    "        super(ConvolutionLayer, self).__init__()\n",
    "        self.dimN, self.dimM, self.dimL, self.dimK = dim\n",
    "        if self.dimN != out_channels:\n",
    "            raise ValueError(f'{self.dimN} is not equal to {out_channels}')\n",
    "        if self.dimM != in_channels:\n",
    "            raise ValueError(f'{self.dimM} is not equal to {in_channels}')\n",
    "        self.rank = rank\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return F.conv2d(input = z, weight = weights(self.rank, self.dimN, self.dimM, self.dimL, self.dimK))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2de6c",
   "metadata": {},
   "source": [
    "### Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f09f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1, 3, 5, 5)  # input\n",
    "W = torch.randn(2, 3, 2, 2)  # weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4344679a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_layer = ConvolutionLayer(3, 64, 2, (64,3,4,4))\n",
    "C = conv_layer(z)  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5db1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "tensor([[[[-0.3097, -1.1636,  0.6096, -0.4294,  0.3548],\n",
      "          [ 1.1298,  0.2220,  0.7470,  0.1938, -1.1761],\n",
      "          [-0.6657, -0.2547,  1.6188, -0.5290,  0.5796],\n",
      "          [-0.3994, -0.8395,  0.2908,  0.6088,  0.6565],\n",
      "          [-0.0356,  0.1512,  0.8814, -0.7965, -0.2351]],\n",
      "\n",
      "         [[ 0.3865,  0.8598,  0.9623,  1.3150,  0.0598],\n",
      "          [ 2.0278,  2.4628,  0.6752,  1.2212, -0.0390],\n",
      "          [ 1.4419, -2.7861, -0.2695, -0.9984,  1.5148],\n",
      "          [ 0.8156, -1.2264,  0.6983, -1.2612, -0.4677],\n",
      "          [ 0.4803,  0.7049, -0.5394,  0.7509, -0.9374]],\n",
      "\n",
      "         [[ 0.3382,  0.4085, -1.7307,  0.3687,  0.7655],\n",
      "          [ 0.2558,  1.2210,  0.9032,  1.5146,  0.1163],\n",
      "          [-0.1457, -0.7474, -1.0655,  0.8627,  0.6507],\n",
      "          [ 1.1998,  0.2671,  1.6609, -0.2052, -0.3969],\n",
      "          [-0.3965,  0.8824,  0.9324, -2.0103, -0.5503]]]])\n",
      "wights:\n",
      "tensor([[[[-1.3735,  2.1461],\n",
      "          [-0.0203,  1.5852]],\n",
      "\n",
      "         [[ 0.1329, -0.3977],\n",
      "          [ 1.2068, -0.0409]],\n",
      "\n",
      "         [[ 0.1872,  1.1088],\n",
      "          [-0.7105,  0.2537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9061, -0.7981],\n",
      "          [ 0.9453, -1.3372]],\n",
      "\n",
      "         [[-0.4334,  0.6171],\n",
      "          [ 1.1289,  0.3133]],\n",
      "\n",
      "         [[-0.4271,  0.0417],\n",
      "          [-0.9547, -0.9368]]]])\n",
      "output:\n",
      "tensor([[[[1.6072, 1.7875],\n",
      "          [2.7044, 2.3763]],\n",
      "\n",
      "         [[1.5788, 1.7154],\n",
      "          [2.7831, 2.3809]],\n",
      "\n",
      "         [[1.8657, 2.0219],\n",
      "          [3.3048, 2.8194]],\n",
      "\n",
      "         [[0.9610, 1.3685],\n",
      "          [0.6812, 1.0759]],\n",
      "\n",
      "         [[0.6641, 0.4596],\n",
      "          [1.9886, 1.3030]],\n",
      "\n",
      "         [[1.0931, 0.7949],\n",
      "          [3.1529, 2.1003]],\n",
      "\n",
      "         [[1.0431, 1.0568],\n",
      "          [2.0777, 1.6611]],\n",
      "\n",
      "         [[1.0174, 0.7933],\n",
      "          [2.7677, 1.8934]],\n",
      "\n",
      "         [[1.0979, 1.4653],\n",
      "          [1.0850, 1.3423]],\n",
      "\n",
      "         [[1.0743, 0.9800],\n",
      "          [2.4784, 1.8356]],\n",
      "\n",
      "         [[1.4279, 1.3492],\n",
      "          [3.1486, 2.3861]],\n",
      "\n",
      "         [[0.6190, 0.8512],\n",
      "          [0.5332, 0.7278]],\n",
      "\n",
      "         [[1.6528, 1.7899],\n",
      "          [2.9320, 2.4993]],\n",
      "\n",
      "         [[0.8160, 1.2847],\n",
      "          [0.1955, 0.7724]],\n",
      "\n",
      "         [[0.7843, 0.7527],\n",
      "          [1.6934, 1.2973]],\n",
      "\n",
      "         [[1.5681, 1.8260],\n",
      "          [2.3825, 2.2240]],\n",
      "\n",
      "         [[1.1632, 0.8606],\n",
      "          [3.3094, 2.2182]],\n",
      "\n",
      "         [[0.7452, 1.2162],\n",
      "          [0.0444, 0.6560]],\n",
      "\n",
      "         [[1.2704, 1.5543],\n",
      "          [1.6960, 1.7155]],\n",
      "\n",
      "         [[1.3545, 1.6221],\n",
      "          [1.9181, 1.8695]],\n",
      "\n",
      "         [[0.6809, 0.8339],\n",
      "          [0.9066, 0.9186]],\n",
      "\n",
      "         [[1.2679, 1.2749],\n",
      "          [2.5555, 2.0301]],\n",
      "\n",
      "         [[1.2313, 0.8883],\n",
      "          [3.5738, 2.3741]],\n",
      "\n",
      "         [[1.7981, 1.8499],\n",
      "          [3.4933, 2.8309]],\n",
      "\n",
      "         [[1.6567, 1.8574],\n",
      "          [2.7411, 2.4323]],\n",
      "\n",
      "         [[1.0275, 0.9180],\n",
      "          [2.4304, 1.7777]],\n",
      "\n",
      "         [[1.2996, 1.3531],\n",
      "          [2.4747, 2.0276]],\n",
      "\n",
      "         [[1.6543, 1.8725],\n",
      "          [2.6819, 2.4084]],\n",
      "\n",
      "         [[1.1782, 1.2352],\n",
      "          [2.2171, 1.8284]],\n",
      "\n",
      "         [[1.0063, 0.7202],\n",
      "          [2.9387, 1.9469]],\n",
      "\n",
      "         [[1.3566, 1.5025],\n",
      "          [2.3025, 2.0131]],\n",
      "\n",
      "         [[0.7150, 0.7634],\n",
      "          [1.3025, 1.0938]],\n",
      "\n",
      "         [[1.0506, 1.3877],\n",
      "          [1.0832, 1.3010]],\n",
      "\n",
      "         [[0.6758, 0.8282],\n",
      "          [0.8978, 0.9109]],\n",
      "\n",
      "         [[0.4699, 0.5521],\n",
      "          [0.6987, 0.6609]],\n",
      "\n",
      "         [[0.8175, 0.8313],\n",
      "          [1.6189, 1.2984]],\n",
      "\n",
      "         [[0.2624, 0.4061],\n",
      "          [0.0847, 0.2564]],\n",
      "\n",
      "         [[1.2376, 0.9379],\n",
      "          [3.4516, 2.3344]],\n",
      "\n",
      "         [[1.7907, 1.8395],\n",
      "          [3.4878, 2.8225]],\n",
      "\n",
      "         [[0.4928, 0.4734],\n",
      "          [1.0623, 0.8145]],\n",
      "\n",
      "         [[0.7415, 0.8420],\n",
      "          [1.1937, 1.0764]],\n",
      "\n",
      "         [[1.5259, 1.5985],\n",
      "          [2.8752, 2.3695]],\n",
      "\n",
      "         [[1.3923, 1.6830],\n",
      "          [1.9226, 1.9036]],\n",
      "\n",
      "         [[0.8424, 0.6625],\n",
      "          [2.2742, 1.5613]],\n",
      "\n",
      "         [[1.0414, 0.9513],\n",
      "          [2.3982, 1.7778]],\n",
      "\n",
      "         [[1.7644, 1.9495],\n",
      "          [3.0089, 2.6234]],\n",
      "\n",
      "         [[0.6830, 1.1237],\n",
      "          [0.0123, 0.5907]],\n",
      "\n",
      "         [[0.7244, 1.0171],\n",
      "          [0.5587, 0.8276]],\n",
      "\n",
      "         [[0.7804, 0.9364],\n",
      "          [1.0991, 1.0749]],\n",
      "\n",
      "         [[0.6808, 0.6675],\n",
      "          [1.4253, 1.1096]],\n",
      "\n",
      "         [[0.4248, 0.4823],\n",
      "          [0.6840, 0.6167]],\n",
      "\n",
      "         [[1.4756, 1.6255],\n",
      "          [2.5317, 2.1997]],\n",
      "\n",
      "         [[1.2322, 1.0410],\n",
      "          [3.1021, 2.2010]],\n",
      "\n",
      "         [[1.0166, 1.3875],\n",
      "          [0.9084, 1.2073]],\n",
      "\n",
      "         [[0.8079, 1.2805],\n",
      "          [0.1667, 0.7548]],\n",
      "\n",
      "         [[0.5106, 0.6639],\n",
      "          [0.5593, 0.6444]],\n",
      "\n",
      "         [[1.0948, 1.1284],\n",
      "          [2.1208, 1.7214]],\n",
      "\n",
      "         [[1.0023, 0.7341],\n",
      "          [2.8750, 1.9199]],\n",
      "\n",
      "         [[0.4321, 0.6440],\n",
      "          [0.2167, 0.4507]],\n",
      "\n",
      "         [[0.9291, 1.3919],\n",
      "          [0.4437, 0.9610]],\n",
      "\n",
      "         [[0.2577, 0.2523],\n",
      "          [0.5408, 0.4205]],\n",
      "\n",
      "         [[0.6270, 0.9600],\n",
      "          [0.2349, 0.6247]],\n",
      "\n",
      "         [[1.1777, 1.4359],\n",
      "          [1.5882, 1.5962]],\n",
      "\n",
      "         [[0.2927, 0.2392],\n",
      "          [0.7622, 0.5322]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"input:\")\n",
    "print(z)\n",
    "print(\"wights:\")\n",
    "print(W)\n",
    "print(\"output:\")\n",
    "print(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
